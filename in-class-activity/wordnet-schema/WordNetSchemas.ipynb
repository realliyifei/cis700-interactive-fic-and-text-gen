{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# In-Class Activity: WordNet Schemas\n",
        "\n",
        "In this assignment, you will be getting hands-on experience with working with WordNet and manipulating the data.\n",
        "\n",
        "In the problems below, pretend that you (or, rather, your agent) are in the middle of playing a text adventure game. Different characters are asking for various items, but you don't have the exact items. You will be using WordNet to form schemas of your inventory items and going your representations to find the most similar item."
      ],
      "metadata": {
        "id": "C-L4o-OnpMNU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukxhQxiooue2"
      },
      "source": [
        "## Stanza\n",
        "\n",
        "I've setup Stanford's Stanza parser for parsing sentences. Install it and download the models here. You might need to restart the runtime afterward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x7KgiGoPKnQt"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!python -m pip install stanza\n",
        "import stanza\n",
        "stanza.download('en')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvQ6mwL7UrXN"
      },
      "source": [
        "### Calling Stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_IpCvvOlYjH",
        "outputId": "7814d228-1a0a-4e0a-e3e7-c5e8258a97b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'deprel': 'advmod',\n",
              "   'end_char': 3,\n",
              "   'feats': 'PronType=Int',\n",
              "   'head': 2,\n",
              "   'id': 1,\n",
              "   'lemma': 'how',\n",
              "   'ner': 'O',\n",
              "   'start_char': 0,\n",
              "   'text': 'How',\n",
              "   'upos': 'ADV',\n",
              "   'xpos': 'WRB'},\n",
              "  {'deprel': 'advcl',\n",
              "   'end_char': 15,\n",
              "   'feats': 'Degree=Pos',\n",
              "   'head': 5,\n",
              "   'id': 2,\n",
              "   'lemma': 'appropriate',\n",
              "   'ner': 'O',\n",
              "   'start_char': 4,\n",
              "   'text': 'appropriate',\n",
              "   'upos': 'ADJ',\n",
              "   'xpos': 'JJ'},\n",
              "  {'deprel': 'punct',\n",
              "   'end_char': 16,\n",
              "   'head': 5,\n",
              "   'id': 3,\n",
              "   'lemma': ',',\n",
              "   'ner': 'O',\n",
              "   'start_char': 15,\n",
              "   'text': ',',\n",
              "   'upos': 'PUNCT',\n",
              "   'xpos': ','},\n",
              "  {'deprel': 'nsubj',\n",
              "   'end_char': 20,\n",
              "   'feats': 'Case=Nom|Number=Sing|Person=2|PronType=Prs',\n",
              "   'head': 5,\n",
              "   'id': 4,\n",
              "   'lemma': 'you',\n",
              "   'ner': 'O',\n",
              "   'start_char': 17,\n",
              "   'text': 'you',\n",
              "   'upos': 'PRON',\n",
              "   'xpos': 'PRP'},\n",
              "  {'deprel': 'root',\n",
              "   'end_char': 26,\n",
              "   'feats': 'Mood=Ind|Number=Sing|Person=2|Tense=Pres|VerbForm=Fin',\n",
              "   'head': 0,\n",
              "   'id': 5,\n",
              "   'lemma': 'fight',\n",
              "   'ner': 'O',\n",
              "   'start_char': 21,\n",
              "   'text': 'fight',\n",
              "   'upos': 'VERB',\n",
              "   'xpos': 'VBP'},\n",
              "  {'deprel': 'case',\n",
              "   'end_char': 31,\n",
              "   'head': 8,\n",
              "   'id': 6,\n",
              "   'lemma': 'like',\n",
              "   'ner': 'O',\n",
              "   'start_char': 27,\n",
              "   'text': 'like',\n",
              "   'upos': 'ADP',\n",
              "   'xpos': 'IN'},\n",
              "  {'deprel': 'det',\n",
              "   'end_char': 33,\n",
              "   'feats': 'Definite=Ind|PronType=Art',\n",
              "   'head': 8,\n",
              "   'id': 7,\n",
              "   'lemma': 'a',\n",
              "   'ner': 'O',\n",
              "   'start_char': 32,\n",
              "   'text': 'a',\n",
              "   'upos': 'DET',\n",
              "   'xpos': 'DT'},\n",
              "  {'deprel': 'obl',\n",
              "   'end_char': 37,\n",
              "   'feats': 'Number=Sing',\n",
              "   'head': 5,\n",
              "   'id': 8,\n",
              "   'lemma': 'cow',\n",
              "   'ner': 'O',\n",
              "   'start_char': 34,\n",
              "   'text': 'cow',\n",
              "   'upos': 'NOUN',\n",
              "   'xpos': 'NN'},\n",
              "  {'deprel': 'punct',\n",
              "   'end_char': 38,\n",
              "   'head': 5,\n",
              "   'id': 9,\n",
              "   'lemma': '.',\n",
              "   'ner': 'O',\n",
              "   'start_char': 37,\n",
              "   'text': '.',\n",
              "   'upos': 'PUNCT',\n",
              "   'xpos': '.'}]]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import stanza\n",
        "import json\n",
        "nlp = stanza.Pipeline('en', processors='pos,lemma,tokenize,ner,depparse, mwt, constituency')\n",
        "\n",
        "# parsing an example sentence\n",
        "parse = nlp(\"How appropriate, you fight like a cow.\")\n",
        "y = json.loads(str(parse))\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuI9RGzJ94X9"
      },
      "source": [
        "# WordNet\n",
        "\n",
        "\n",
        "Below is an example of how WordNet functions. Dog is a hyponym (offspring) of canine, which is a hyponym of carnivore. So canine is a hypernym (ancestor) of dog.\n",
        "\n",
        "![See text above](https://drive.google.com/uc?id=1qhhg-CtXzN8yDcdQCx7ydkEnKYVX4AUj)\n",
        "\n",
        "Each word has multiple dictionary entries with different meanings. Each one is called a \"Synset\" and is given a tag. For example, Synset('dog.n.01') where dog is the word, \"n\" is the part of speech (noun), and 01 is the definition number (this refers to the definition for the animal _dog_).\n",
        "\n",
        "\n",
        "You can play with it online here: http://wordnetweb.princeton.edu/perl/webwn\n",
        "\n",
        "\n",
        "### Citation:\n",
        "```\n",
        "@article{miller1995wordnet,\n",
        "  title={WordNet: a lexical database for English},\n",
        "  author={Miller, George A.},\n",
        "  journal={Communications of the ACM},\n",
        "  volume={38},\n",
        "  number={11},\n",
        "  pages={39--41},\n",
        "  year={1995},\n",
        "  publisher={ACM New York, NY, USA}\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1LjnvrV-LbA"
      },
      "source": [
        "### Using WordNet: NLTK\n",
        "\n",
        "# Follow [this link](https://www.nltk.org/howto/wordnet.html) to a tutorial on using NLTK for WordNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZRW2AnLULBWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01a591ab-5f1d-4b88-86a0-bf77f5b810b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Task: Create a schema for your inventory\n",
        "\n",
        "In the problems below, an NPC is asking for a particular item, but you don't have anything in your inventory with that name.\n",
        "\n",
        "For each item in your inventory, I'd like you to create a schema---some way of formalizing the information. And you will write code to look through each schema to see which inventory item is appropriate to use in the scenario by comparing the information in the schemas to the request."
      ],
      "metadata": {
        "id": "6FW4byB3sh4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Admittedly, this isn't the fastest way of comparing words, since you can just do the following, but I want you to practice making schemas!"
      ],
      "metadata": {
        "id": "SVuK1Bs_tNp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn"
      ],
      "metadata": {
        "id": "aG-mP8yxZKF4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The quick way to do it\n",
        "dog = wn.synsets('dog')\n",
        "cat = wn.synsets('cat')[0]\n",
        "print(dog) #see all possible definitions of \"dog\"\n",
        "dog = dog[0] #select the first one\n",
        "print(dog.path_similarity(cat, simulate_root=False)) #find similarity between the two words"
      ],
      "metadata": {
        "id": "9fKS6_yQtMpi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c3eb056-0c0a-4bc2-e324-d4991d982500"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('dog.n.01'), Synset('frump.n.01'), Synset('dog.n.03'), Synset('cad.n.01'), Synset('frank.n.02'), Synset('pawl.n.01'), Synset('andiron.n.01'), Synset('chase.v.01')]\n",
            "0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill out the code below. Keep the WordNet online demo open to help you figure out what you should be saving.\n",
        "\n",
        "### Problem 1"
      ],
      "metadata": {
        "id": "gqG8A1UWykjs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "BeqBj9iZ-A-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e24c3edc-9ac2-4448-bff7-42d7859e158b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "do\n",
            "you\n",
            "have\n",
            "any\n",
            "sockeye\n",
            "?\n",
            "Clostest inventory item: tuna\n",
            "Clostest inventory item shema: Synset('red_salmon.n.01') and Synset('scombroid.n.01')\n"
          ]
        }
      ],
      "source": [
        "# your inventory\n",
        "inventory = [\"tuna\", \"glasses\", \"salmon\", \"fish\", \"sushi\", \"shoe\"]\n",
        "\n",
        "#TODO create a representation of each of these items\n",
        "inv_schema = {}\n",
        "for i in inventory:\n",
        "  inv_item = wn.synsets(i) #TODO: look up the synset for the word\n",
        "  inv_facts = []\n",
        "  for ss in inv_item:\n",
        "      inv_facts += ss.hypernyms() \n",
        "      inv_facts += ss.hyponyms()\n",
        "  #TODO: fill inv_facts with information from Wordnet relevant to your schema\n",
        "  # Store hypernyms, hyponymns, part meronym, or whatever you need to find the answer\n",
        "  # You might have to go a couple words deep\n",
        "  inv_schema[i] = inv_facts\n",
        "\n",
        "# Added by yifei\n",
        "smallest_similarity_score = 1000\n",
        "closest_inventory_item = ''\n",
        "closest_inventory_item_schema = ''\n",
        "\n",
        "npc_request = nlp(\"Do you have any sockeye?\")\n",
        "request_json = json.loads(str(npc_request))[0]\n",
        "for word in request_json:\n",
        "  print(word['lemma'])\n",
        "  #TODO: compare to your schemas\n",
        "  # Yifei: Should catch the key word more automatically, but here for convenience\n",
        "  if word['lemma'] == 'sockeye':\n",
        "    target_item_synset_list =  wn.synsets(word['lemma']) \n",
        "    for inventory_item, inventory_item_synset_list in inv_schema.items():\n",
        "      for target_item_synset in target_item_synset_list:\n",
        "        for inventory_item_synset in inventory_item_synset_list:\n",
        "          similarity_score = target_item_synset.path_similarity(inventory_item_synset)\n",
        "        #   print(target_item_synset, inventory_item_synset, similarity_score)  \n",
        "          if similarity_score is not None:\n",
        "            if similarity_score < smallest_similarity_score:\n",
        "                smallest_similarity_score = similarity_score\n",
        "                closest_inventory_item = inventory_item            \n",
        "                closest_inventory_item_schema = [target_item_synset, inventory_item_synset]\n",
        "\n",
        "#TODO: print the closest inventory item and what part of the schema was used to compare it \n",
        "print('Clostest inventory item:', closest_inventory_item)\n",
        "print('Clostest inventory item shema:', closest_inventory_item_schema[0], 'and', closest_inventory_item_schema[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem 2"
      ],
      "metadata": {
        "id": "YZ_dL3jQyrPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "# your inventory\n",
        "inventory = [\"oranges\", \"lipstick\", \"tree\", \"garden\", \"sap\", \"diagram\"]\n",
        "\n",
        "#TODO create a representation of each of these items\n",
        "inv_schema = {}\n",
        "for i in inventory:\n",
        "  inv_item = wn.synsets(i) #TODO: look up the synset for the word\n",
        "  inv_facts = []\n",
        "  for ss in inv_item:\n",
        "      inv_facts += ss.hypernyms() \n",
        "      inv_facts += ss.hyponyms()\n",
        "  #TODO: fill inv_facts with information from Wordnet relevant to your schema\n",
        "  # Store hypernyms, hyponymns, part meronym, or whatever you need to find the answer\n",
        "  # You might have to go a couple words deep\n",
        "  inv_schema[i] = inv_facts\n",
        "\n",
        "# Added by yifei\n",
        "smallest_similarity_score = 1000\n",
        "closest_inventory_item = ''\n",
        "closest_inventory_item_schema = []\n",
        "\n",
        "npc_request = nlp(\"Do you have any sticks?\")\n",
        "request_json = json.loads(str(npc_request))[0]\n",
        "for word in request_json:\n",
        "  print(word['lemma'])\n",
        "  #TODO: compare to your schemas\n",
        "  # Yifei: Should catch the key word more automatically, but here for convenience\n",
        "  if word['lemma'] == 'stick':\n",
        "    target_item_synset_list =  wn.synsets(word['lemma']) \n",
        "    for inventory_item, inventory_item_synset_list in inv_schema.items():\n",
        "      for target_item_synset in target_item_synset_list:\n",
        "        for inventory_item_synset in inventory_item_synset_list:\n",
        "          similarity_score = target_item_synset.path_similarity(inventory_item_synset)\n",
        "        #   print(target_item_synset, inventory_item_synset, similarity_score)  \n",
        "          if similarity_score is not None:\n",
        "            if similarity_score < smallest_similarity_score:\n",
        "                smallest_similarity_score = similarity_score\n",
        "                closest_inventory_item = inventory_item            \n",
        "                closest_inventory_item_schema = [target_item_synset, inventory_item_synset]\n",
        "\n",
        "#TODO: print the closest inventory item and what part of the schema was used to compare it\n",
        "print('Clostest inventory item:', closest_inventory_item)\n",
        "print('Clostest inventory item shema:', closest_inventory_item_schema[0], 'and', closest_inventory_item_schema[1])"
      ],
      "metadata": {
        "id": "0q22vfQfu_U5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f5bc895-6cd2-4a01-d7fb-29bce63e71a2"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "do\n",
            "you\n",
            "have\n",
            "any\n",
            "stick\n",
            "?\n",
            "Clostest inventory item: oranges\n",
            "Clostest inventory item shema: Synset('pin.n.05') and Synset('bergamot.n.01')\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of WordNetSchemas",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}